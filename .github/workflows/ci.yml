name: CI

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  backend:
    name: Backend (Python)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: .
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt', 'requirements-analytics.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-analytics.txt

      - name: Test Analytics Integration
        run: |
          python -c "
          import sys
          try:
              import supabase, sqlalchemy, pandas, schedule
              print('‚úÖ Analytics dependencies installed successfully')
          except ImportError as e:
              print(f'‚ùå Missing analytics dependency: {e}')
              sys.exit(1)
          "


  frontend:
    name: Frontend (Node)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Build
        env:
          CI: false
        run: npm run build


  deploy:
    name: Deploy to Linode
    runs-on: ubuntu-latest
    needs: [backend, frontend]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Prepare artifact (filter out dev caches)
        run: |
          rm -rf .git

      - name: Upload project to server (key or password)
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          password: ${{ secrets.SSH_PASSWORD }}
          source: "."
          target: "${{ secrets.REMOTE_APP_DIR }}"

      - name: Run remote deployment (key or password)
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          password: ${{ secrets.SSH_PASSWORD }}
          script_stop: true
          script: |
            set -euo pipefail
            export APP_DIR=${{ secrets.REMOTE_APP_DIR }}
            # Install Docker & Compose if missing
            if ! command -v docker >/dev/null 2>&1; then
              curl -fsSL https://get.docker.com | sh
              systemctl enable docker || true
              systemctl start docker || true
            fi
            if ! docker compose version >/dev/null 2>&1; then
              DOCKER_CONFIG=${HOME}/.docker mkdir -p ${DOCKER_CONFIG}/cli-plugins
              curl -SL https://github.com/docker/compose/releases/download/v2.29.7/docker-compose-linux-$(uname -m) -o ${DOCKER_CONFIG}/cli-plugins/docker-compose
              chmod +x ${DOCKER_CONFIG}/cli-plugins/docker-compose
            fi

            mkdir -p "$APP_DIR"
            cd "$APP_DIR"

            # No local storage directories needed - using Supabase Storage
            
            # Ensure env files exist (backend .env)
            if [ -n "${{ secrets.BACKEND_ENV }}" ]; then
              echo "${{ secrets.BACKEND_ENV }}" > .env
            fi
            # Frontend env
            if [ -n "${{ secrets.FRONTEND_ENV }}" ]; then
              echo "${{ secrets.FRONTEND_ENV }}" > frontend/.env.production
            elif [ ! -f frontend/.env.production ]; then
              echo "REACT_APP_API_URL=/api" > frontend/.env.production
            fi

            # Stop services before rebuild to handle SQLite file locks
            docker compose -f docker-compose.yml down || true
            
            # Build and start services
            docker compose -f docker-compose.yml build --no-cache
            docker compose -f docker-compose.yml up -d
            
            # Deploy Analytics
            echo "üîß Deploying Analytics System..."
            
            # Install analytics dependencies in the running container
            docker compose exec -T api pip install supabase sqlalchemy pandas schedule requests python-dotenv || true
            
            # Copy analytics files to container
            docker compose exec -T api mkdir -p /app/analytics || true
            docker cp analytics_export.py $(docker compose ps -q api):/app/analytics_export.py || true
            docker cp periodic_analytics.py $(docker compose ps -q api):/app/periodic_analytics.py || true
            docker cp analytics_dashboard.py $(docker compose ps -q api):/app/analytics_dashboard.py || true
            docker cp integrate_analytics.py $(docker compose ps -q api):/app/integrate_analytics.py || true
            
            # Set up analytics cron jobs on the host (every hour)
            echo "‚è∞ Setting up analytics cron jobs (every hour)..."
            (crontab -l 2>/dev/null; echo "# Joborra Analytics Export Jobs - Every Hour") | crontab - || true
            (crontab -l 2>/dev/null; echo "0 * * * * cd $APP_DIR && docker compose exec -T api python /app/analytics_export.py >> /var/log/joborra/analytics.log 2>&1") | crontab - || true
            
            # Create analytics log directory
            mkdir -p /var/log/joborra
            touch /var/log/joborra/analytics.log
            
            # Test analytics deployment
            echo "üß™ Testing analytics deployment..."
            docker compose exec -T api python -c "import sys; import supabase, sqlalchemy, pandas; print('‚úÖ Analytics dependencies available in container')" || echo "‚ö†Ô∏è Analytics dependency issue"
            
            echo "‚úÖ Analytics deployment completed"
            
            # Verify deployment
            sleep 10
            docker compose logs api --tail=50
            # Cleanup old images
            docker image prune -f || true
